{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f51c2f1f-c9eb-46bd-87a0-bfed13821997",
   "metadata": {
    "executionInfo": {
     "elapsed": 6671,
     "status": "ok",
     "timestamp": 1748006552026,
     "user": {
      "displayName": "JORDI GUILLÉN GONZÁLEZ",
      "userId": "15811336653197258391"
     },
     "user_tz": -120
    },
    "id": "f51c2f1f-c9eb-46bd-87a0-bfed13821997"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3eb8a-3bbd-4c8e-8232-69ebe41d045c",
   "metadata": {
    "id": "4ac3eb8a-3bbd-4c8e-8232-69ebe41d045c"
   },
   "source": [
    "# Seminar 5 - Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb921ac-6386-4074-81ae-18756059b2ae",
   "metadata": {},
   "source": [
    "Javier González Otero - 243078\n",
    "\n",
    "Jordi Guillén González - 253027\n",
    "\n",
    "David Sánchez Maldonado - 253798"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119a918-efd1-4f7a-92c9-7e1c5a97a10e",
   "metadata": {
    "id": "1119a918-efd1-4f7a-92c9-7e1c5a97a10e"
   },
   "source": [
    "## Part 0: Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe68498-e2f6-4112-92db-fcdcd358e294",
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1748009659904,
     "user": {
      "displayName": "JORDI GUILLÉN GONZÁLEZ",
      "userId": "15811336653197258391"
     },
     "user_tz": -120
    },
    "id": "fbe68498-e2f6-4112-92db-fcdcd358e294"
   },
   "outputs": [],
   "source": [
    "file_path_clients = \"data/client_datasets/\"  # Path to the directory containing training data for each client\n",
    "\n",
    "# Lists to store training features and labels DataFrames for each client\n",
    "train_features_dfs = []\n",
    "train_labels_dfs = []\n",
    "\n",
    "# Loop over the 10 clients\n",
    "for client_id in range(1, 11):\n",
    "    # Load training features and labels for the current client\n",
    "    features_df = pd.read_csv(f\"{file_path_clients}client_{client_id}_features.csv\", header=None)\n",
    "    labels_df = pd.read_csv(f\"{file_path_clients}client_{client_id}_labels.csv\", header=None)\n",
    "\n",
    "    # Append the loaded data to the lists\n",
    "    train_features_dfs.append(features_df)\n",
    "    train_labels_dfs.append(labels_df)\n",
    "\n",
    "# Load test features and labels\n",
    "test_features_df = pd.read_csv('data/test_features.csv', header=None)\n",
    "test_labels_df = pd.read_csv('data/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22246541-b81d-4ba7-82e6-12e4690578d2",
   "metadata": {},
   "source": [
    "**Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6352e7b-165a-4327-85b0-dddf80a64227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Checks for missing (NaN) values in a DataFrame.\n",
    "\n",
    "    Prints the total number of missing values and \n",
    "    the row indices where they occur, if any.\n",
    "    \"\"\"\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    \n",
    "    if total_missing > 0:\n",
    "        print(f\"Missing values found: {total_missing}\")\n",
    "        missing_rows = df[df.isnull().any(axis=1)]\n",
    "        print(f\"Rows with missing values:\\n{missing_rows.index.tolist()}\")\n",
    "    else:\n",
    "        print(\"No missing values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f2ebb38-aae4-4782-9502-1e4a85392d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training data (features and labels):\n",
      "\n",
      "Client 1\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 2\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 3\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 4\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 5\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 6\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 7\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 8\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 9\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 10\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Checking test data (features and labels):\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking training data (features and labels):\")\n",
    "for i in range(10):  # 10 clients\n",
    "    print(f\"\\nClient {i+1}\")\n",
    "    print(\"- Features:\")\n",
    "    check_missing_values(train_features_dfs[i])\n",
    "    print(\"- Labels:\")\n",
    "    check_missing_values(train_labels_dfs[i])\n",
    "print(\"\\nChecking test data (features and labels):\")\n",
    "print(\"- Features:\")\n",
    "check_missing_values(test_features_df)\n",
    "print(\"- Labels:\")\n",
    "check_missing_values(test_labels_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0e744-56ff-482d-a50c-5b813ac82178",
   "metadata": {},
   "source": [
    "No cleaning is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ec3ce-3668-4b19-8b43-50c2168187cc",
   "metadata": {},
   "source": [
    "**Obtain the data proportion associated to each client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6ad4fc6-846e-4fb0-8143-69dc4fd45150",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_client_1 = len(train_features_dfs[0])\n",
    "num_samples_client_2 = len(train_features_dfs[1])\n",
    "num_samples_client_3 = len(train_features_dfs[2])\n",
    "num_samples_client_4 = len(train_features_dfs[3])\n",
    "num_samples_client_5 = len(train_features_dfs[4])\n",
    "num_samples_client_6 = len(train_features_dfs[5])\n",
    "num_samples_client_7 = len(train_features_dfs[6])\n",
    "num_samples_client_8 = len(train_features_dfs[7])\n",
    "num_samples_client_9 = len(train_features_dfs[8])\n",
    "num_samples_client_10 = len(train_features_dfs[9])\n",
    "\n",
    "total_samples = (\n",
    "    num_samples_client_1 + num_samples_client_2 + num_samples_client_3 +\n",
    "    num_samples_client_4 + num_samples_client_5 + num_samples_client_6 +\n",
    "    num_samples_client_7 + num_samples_client_8 + num_samples_client_9 +\n",
    "    num_samples_client_10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596381c-de94-4cba-9e7c-6bc6ec7e6f8e",
   "metadata": {
    "id": "c596381c-de94-4cba-9e7c-6bc6ec7e6f8e"
   },
   "source": [
    "## Part 1 - ML model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_Ms927kCTiyP",
   "metadata": {
    "id": "_Ms927kCTiyP"
   },
   "source": [
    "De momenento uso el svm del semi 2 que ha dicho que lo podemos usar. Se puede cambiar al que queramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "VBGvGS3cR4De",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748006674654,
     "user": {
      "displayName": "JORDI GUILLÉN GONZÁLEZ",
      "userId": "15811336653197258391"
     },
     "user_tz": -120
    },
    "id": "VBGvGS3cR4De"
   },
   "outputs": [],
   "source": [
    "def train_svm_model(X_train, y_train, kernel='rbf', C=1.0, gamma='scale'):\n",
    "    '''\n",
    "    Trains a Support Vector Machine (SVM) classifier on the given CSI feature data.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (pd.DataFrame or np.ndarray): CSI features (shape: [n_samples, 270]).\n",
    "    - y_train (pd.Series or np.ndarray): Labels (values from 1 to 5).\n",
    "    - kernel (str): Kernel type ('linear', 'rbf', 'poly', etc.)\n",
    "    - C (float): Regularization parameter.\n",
    "    - gamma (str or float): Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained SVM model.\n",
    "    - scaler: StandardScaler used for normalization.\n",
    "    '''\n",
    "    # flatten train labels\n",
    "    y_train = y_train.iloc[0, :].values.ravel()\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Train SVM\n",
    "    svm = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    svm.fit(X_scaled, y_train)\n",
    "\n",
    "    return svm, scaler\n",
    "\n",
    "def predict_with_svm(model, scaler, X_test):\n",
    "    '''\n",
    "    Generates predictions on the test dataset using a trained SVM model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained SVM classifier.\n",
    "    - scaler: StandardScaler used during training.\n",
    "    - X_test (pd.DataFrame or np.ndarray): Test features.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Predicted labels for the test samples.\n",
    "    '''\n",
    "    X_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dc3ee6a-a1b7-49c5-b301-5f308273eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=270, hidden_dim=128, output_dim=12):\n",
    "        super(PoseClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)  # logits (use CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6lnOAvTSQuaT",
   "metadata": {
    "id": "6lnOAvTSQuaT"
   },
   "source": [
    "## Part 2 - Preparation of the FL setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b54454b1-7285-4d3e-b58a-bff54f8ee8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fl_round_fn(clients_data, selected_clients, global_model, epochs=5, batch_size=32, lr=0.01):\n",
    "    \"\"\"\n",
    "    Performs local training for each selected client and returns their updated weights and dataset sizes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    updates : list of dict\n",
    "        List of state_dicts with updated model weights.\n",
    "    sizes : list of int\n",
    "        Number of training samples for each client.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    sizes = []\n",
    "\n",
    "    for client_id in selected_clients:\n",
    "        X_train, y_train = clients_data[client_id]\n",
    "        model = PoseClassifier()\n",
    "        model.load_state_dict(global_model.state_dict())  # Copy global model\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        model.train()\n",
    "        X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y_train.values.ravel(), dtype=torch.long)\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            for xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xb), yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        updates.append(model.state_dict())\n",
    "        sizes.append(len(X_train))\n",
    "\n",
    "    return updates, sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1335b15f-3657-4dde-ae98-26b6afebaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(weight_updates, sizes):\n",
    "    \"\"\"\n",
    "    Performs Federated Averaging over model weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weight_updates : list of state_dicts (models' weights)\n",
    "    sizes : list of int, number of samples per client\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    avg_weights : state_dict representing the averaged model\n",
    "    \"\"\"\n",
    "    total_size = sum(sizes)\n",
    "    avg_weights = {}\n",
    "\n",
    "    for key in weight_updates[0].keys():\n",
    "        avg_weights[key] = sum(\n",
    "            update[key] * (size / total_size)\n",
    "            for update, size in zip(weight_updates, sizes)\n",
    "        )\n",
    "\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb10b9f7-a9d3-43bc-849e-f558659afe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator:\n",
    "    def __init__(self, clients_data, model_class):\n",
    "        \"\"\"\n",
    "        Initialize the Orchestrator with client training data and model class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        clients_data : list of tuples\n",
    "            Each tuple contains (X_train, y_train) for a client.\n",
    "        model_class : callable\n",
    "            A class (e.g., PoseClassifier) that returns a PyTorch model instance.\n",
    "        \"\"\"\n",
    "        self.clients_data = clients_data\n",
    "        self.model_class = model_class\n",
    "        self.global_model = None\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"\n",
    "        Initializes the global model.\n",
    "        \"\"\"\n",
    "        self.global_model = self.model_class()\n",
    "\n",
    "    def select_clients(self, num_clients):\n",
    "        \"\"\"\n",
    "        Randomly selects a subset of clients for the current training round.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_clients : int\n",
    "            Number of clients to select.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list of int : Selected client indices.\n",
    "        \"\"\"\n",
    "        return random.sample(range(len(self.clients_data)), num_clients)\n",
    "\n",
    "    def run_federated_training(self, fl_round_fn, fedavg_fn, num_rounds=5, clients_per_round=3, tolerance=1e-3):\n",
    "        \"\"\"\n",
    "        Runs the Federated Learning process over several rounds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fl_round_fn : function\n",
    "            Function that performs a federated round and returns weights and sizes.\n",
    "        fedavg_fn : function\n",
    "            Function that aggregates model weights using FedAvg.\n",
    "        num_rounds : int\n",
    "            Maximum number of training rounds.\n",
    "        clients_per_round : int\n",
    "            Number of clients selected in each round.\n",
    "        tolerance : float\n",
    "            Convergence criterion based on weight change norm.\n",
    "        \"\"\"\n",
    "        prev_weights = None\n",
    "\n",
    "        for round_num in range(num_rounds):\n",
    "            print(f\"\\n[Round {round_num + 1}] Selecting clients...\")\n",
    "            selected = self.select_clients(clients_per_round)\n",
    "\n",
    "            print(f\"[Round {round_num + 1}] Training local models...\")\n",
    "            updates, sizes = fl_round_fn(self.clients_data, selected, self.global_model)\n",
    "\n",
    "            print(f\"[Round {round_num + 1}] Aggregating with FedAvg...\")\n",
    "            avg_weights = fedavg_fn(updates, sizes)\n",
    "            self.global_model.load_state_dict(avg_weights)\n",
    "\n",
    "            # Check for convergence (optional)\n",
    "            if prev_weights is not None:\n",
    "                deltas = sum(torch.norm(avg_weights[k] - prev_weights[k]).item() for k in avg_weights)\n",
    "                print(f\"[Round {round_num + 1}] Weight change: {deltas:.6f}\")\n",
    "                if deltas < tolerance:\n",
    "                    print(\"[Convergence reached]\")\n",
    "                    break\n",
    "\n",
    "            prev_weights = {k: v.clone().detach() for k, v in avg_weights.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "FyfFc257Q0u6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1748010048386,
     "user": {
      "displayName": "JORDI GUILLÉN GONZÁLEZ",
      "userId": "15811336653197258391"
     },
     "user_tz": -120
    },
    "id": "FyfFc257Q0u6",
    "outputId": "beda3bd9-71a5-4d58-9350-0396c0ddeec3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-224acf3b-fa04-4ab3-bf1d-35727c104540\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>11.1</th>\n",
       "      <th>11.2</th>\n",
       "      <th>11.3</th>\n",
       "      <th>11.4</th>\n",
       "      <th>11.5</th>\n",
       "      <th>11.6</th>\n",
       "      <th>11.7</th>\n",
       "      <th>11.8</th>\n",
       "      <th>11.9</th>\n",
       "      <th>...</th>\n",
       "      <th>9.19</th>\n",
       "      <th>9.20</th>\n",
       "      <th>9.21</th>\n",
       "      <th>9.22</th>\n",
       "      <th>9.23</th>\n",
       "      <th>9.24</th>\n",
       "      <th>9.25</th>\n",
       "      <th>9.26</th>\n",
       "      <th>9.27</th>\n",
       "      <th>9.28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 314 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-224acf3b-fa04-4ab3-bf1d-35727c104540')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-224acf3b-fa04-4ab3-bf1d-35727c104540 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-224acf3b-fa04-4ab3-bf1d-35727c104540');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [11, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 11.7, 11.8, 11.9, 11.10, 11.11, 11.12, 11.13, 11.14, 11.15, 11.16, 11.17, 11.18, 11.19, 11.20, 11.21, 11.22, 11.23, 11.24, 11.25, 11.26, 11.27, 11.28, 11.29, 11.30, 11.31, 11.32, 11.33, 11.34, 11.35, 11.36, 7, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 7.10, 7.11, 7.12, 7.13, 5, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 5.10, 5.11, 5.12, 5.13, 5.14, 5.15, 5.16, 5.17, 5.18, 5.19, 5.20, 5.21, 5.22, 5.23, 5.24, 5.25, 5.26, 5.27, 5.28, 5.29, 5.30, 5.31, 5.32, 5.33, 5.34, 5.35, 5.36, 5.37, 5.38, 5.39, 5.40, 5.41, 5.42, 5.43, 5.44, 5.45, 5.46, 5.47, 5.48, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 314 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming train_svm_model and predict_with_svm functions are defined in the notebook as provided in the context.\n",
    "\n",
    "def run_federated_svm_training(client_datasets, model_params, num_iterations, clients_per_iteration):\n",
    "    \"\"\"\n",
    "    Runs a Federated Learning training process for SVM models.\n",
    "\n",
    "    Args:\n",
    "        client_datasets (list): A list of tuples, where each tuple contains\n",
    "                                (features_df, labels_df) for a client.\n",
    "        model_params (dict): Parameters for the initial global model (e.g., kernel, C, gamma).\n",
    "        num_iterations (int): The number of training iterations.\n",
    "        clients_per_iteration (int): The number of clients to select in each iteration.\n",
    "\n",
    "    Returns:\n",
    "        sklearn.svm.SVC: The final global SVM model after federated training.\n",
    "                         Note: The aggregation for SVM is a placeholder as direct FedAvg\n",
    "                         of SVM parameters is not standard.\n",
    "    \"\"\"\n",
    "    # INITIALIZE GLOBAL ML MODEL\n",
    "    num_clients = len(client_datasets)\n",
    "    scalers = {} # Store scalers for each client\n",
    "\n",
    "    # Train an initial model on the first client's data as a starting point\n",
    "    X_train_initial, y_train_initial = client_datasets[0]\n",
    "    # Flatten labels for training\n",
    "    y_train_initial_flat = y_train_initial.iloc[0, :].values.ravel()\n",
    "    scaler_initial = StandardScaler()\n",
    "    X_scaled_initial = scaler_initial.fit_transform(X_train_initial)\n",
    "    global_model = SVC(**model_params)\n",
    "    global_model.fit(X_scaled_initial, y_train_initial_flat)\n",
    "    scalers[0] = scaler_initial # Store the scaler for the first client\n",
    "\n",
    "    print(\"Global model initialized.\")\n",
    "\n",
    "    # REPEAT STEPS 2-5 UNTIL CONVERGENCE (simulated by num_iterations)\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "        # SELECT A SUBSET OF CLIENTS\n",
    "        selected_clients = random.sample(range(num_clients), clients_per_iteration)\n",
    "        print(f\"Selected clients: {selected_clients}\")\n",
    "\n",
    "        client_models = []\n",
    "        for client_id in selected_clients:\n",
    "            print(f\"Training on client {client_id}...\")\n",
    "\n",
    "            # SEND GLOBAL MODEL TO CLIENTS (simulated by passing the global_model object)\n",
    "            # RETRAINED BY THE CLIENTS USING THEIR LOCAL DATASETS\n",
    "            X_train, y_train = client_datasets[client_id]\n",
    "            # Use the scaler fitted during initial training or fit a new one per client\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_train)\n",
    "            y_train_flat = y_train.iloc[0, :].values.ravel()\n",
    "\n",
    "            client_model = copy.deepcopy(global_model) # Client receives a copy\n",
    "            client_model.fit(X_scaled, y_train_flat)\n",
    "            scalers[client_id] = scaler # Store the scaler for this client\n",
    "\n",
    "            client_models.append(client_model)\n",
    "            print(f\"Training on client {client_id} complete.\")\n",
    "\n",
    "        # RETRIEVE INDIVIDUAL MODELS FROM SELECTED CLIENTS (collected in client_models list)\n",
    "\n",
    "        # AGGREGATE THE INDIVIDUAL CONTRIBUTIONS TO UPDATE THE GLOBAL MODEL (FedAvg placeholder)\n",
    "        print(\"Aggregating models...\")\n",
    "        # Placeholder for FedAvg aggregation for SVM.\n",
    "        # As noted previously, direct averaging of SVM parameters is not standard or effective.\n",
    "        # A proper implementation for SVM in FL would require a different aggregation method.\n",
    "        # For the purpose of demonstrating the FedAvg structure, we print the weights\n",
    "        # but do not perform actual SVM parameter averaging. The global model is not updated here.\n",
    "        total_data_size = sum([client_datasets[i][0].shape[0] for i in selected_clients])\n",
    "        for client_id in selected_clients:\n",
    "             client_data_size = client_datasets[client_id][0].shape[0]\n",
    "             alpha = client_data_size / total_data_size\n",
    "             print(f\"Client {client_id} aggregation weight (alpha): {alpha}\")\n",
    "        # In a real SVM FL, you would update global_model based on client_models here\n",
    "        # using an appropriate SVM aggregation method.\n",
    "        # global_model = new_aggregated_model\n",
    "\n",
    "        print(\"Aggregation complete.\")\n",
    "\n",
    "    print(\"\\nFederated training finished.\")\n",
    "    return global_model\n",
    "\n",
    "# Example usage (assuming you have loaded client data into a list of tuples):\n",
    "# client_datasets = [\n",
    "#     (client_1_features_df, client_1_labels_df),\n",
    "#     (client_2_features_df, client_2_labels_df),\n",
    "#     # Add more client datasets here\n",
    "# ]\n",
    "\n",
    "# Dummy data for demonstration\n",
    "num_clients = 10\n",
    "client_datasets = []\n",
    "for i in range(num_clients):\n",
    "    # Load data files\n",
    "    client_file = f\"{file_path}data/client_datasets/client_{i+1}_features.csv\"\n",
    "    label_file = f\"{file_path}data/client_datasets/client_{i+1}_labels.csv\"\n",
    "    features = pd.read_csv(client_file)#pd.DataFrame(pd.read_csv(client_file))\n",
    "    labels = pd.read_csv(label_file)#pd.DataFrame(pd.read_csv(label_file))\n",
    "    client_datasets.append([features, labels])\n",
    "\n",
    "X_train_initial, y_train_initial = client_datasets[0]\n",
    "y_train_initial.head()\n",
    "\n",
    "# Define model parameters\n",
    "#model_params = {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale'}\n",
    "\n",
    "# Run the federated training function\n",
    "# final_global_model = run_federated_svm_training(\n",
    "#     client_datasets=client_datasets,\n",
    "#     model_params=model_params,\n",
    "#     num_iterations=5,\n",
    "#     clients_per_iteration=2\n",
    "# )\n",
    "\n",
    "# After training, you can use the final_global_model for evaluation or inference.\n",
    "# Note: The scaler used during prediction would depend on how you handle scaling in a real FL scenario.\n",
    "# For this example, let's assume you use the scaler of the first client as a placeholder:\n",
    "# if final_global_model and len(client_datasets) > 0:\n",
    "#     dummy_test_features = pd.DataFrame(np.random.rand(10, 270))\n",
    "#     # Assuming you stored scalers during training and want to use one (e.g., client 0's scaler)\n",
    "#     # You would need a way to access the scalers if the function returned them or stored them globally/in an object\n",
    "#     # For simplicity in this example, this part is commented out as the function doesn't explicitly return scalers.\n",
    "#     # You would need to adapt the function or class to manage scalers for prediction.\n",
    "#     print(\"\\nFinal global model is available for prediction (scaling needs to be handled).\")\n",
    "# else:\n",
    "#      print(\"\\nGlobal model not available after training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sgr0oeM1cfN6",
   "metadata": {
    "id": "Sgr0oeM1cfN6"
   },
   "outputs": [],
   "source": [
    "#Load data files\n",
    "\n",
    "clients_datasets=[]\n",
    "\n",
    "for i in range(10):\n",
    "  client_file = f\"{file_path}data/client_datasets/client_{i+1}_features.csv\"\n",
    "  label_file = f\"{file_path}data/client_datasets/client_{i+1}_labels.csv\"\n",
    "  clients_datasets.append((pd.DataFrame(pd.read_csv(client_file)),pd.DataFrame(pd.read_csv(label_file))))\n",
    "\n",
    "def federated_learning(clients_datasets):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1qrRF3Z6Q0Vh",
   "metadata": {
    "id": "1qrRF3Z6Q0Vh"
   },
   "source": [
    "## Part 3 - Collaborative training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KpIwH78PQ7LM",
   "metadata": {
    "id": "KpIwH78PQ7LM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
