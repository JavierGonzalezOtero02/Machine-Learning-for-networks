{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51c2f1f-c9eb-46bd-87a0-bfed13821997",
   "metadata": {
    "executionInfo": {
     "elapsed": 6671,
     "status": "ok",
     "timestamp": 1748006552026,
     "user": {
      "displayName": "JORDI GUILLÉN GONZÁLEZ",
      "userId": "15811336653197258391"
     },
     "user_tz": -120
    },
    "id": "f51c2f1f-c9eb-46bd-87a0-bfed13821997"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3eb8a-3bbd-4c8e-8232-69ebe41d045c",
   "metadata": {
    "id": "4ac3eb8a-3bbd-4c8e-8232-69ebe41d045c"
   },
   "source": [
    "# Seminar 5 - Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb921ac-6386-4074-81ae-18756059b2ae",
   "metadata": {},
   "source": [
    "Javier González Otero - 243078\n",
    "\n",
    "Jordi Guillén González - 253027\n",
    "\n",
    "David Sánchez Maldonado - 253798"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119a918-efd1-4f7a-92c9-7e1c5a97a10e",
   "metadata": {
    "id": "1119a918-efd1-4f7a-92c9-7e1c5a97a10e"
   },
   "source": [
    "## Part 0: Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe68498-e2f6-4112-92db-fcdcd358e294",
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1748009659904,
     "user": {
      "displayName": "JORDI GUILLÉN GONZÁLEZ",
      "userId": "15811336653197258391"
     },
     "user_tz": -120
    },
    "id": "fbe68498-e2f6-4112-92db-fcdcd358e294"
   },
   "outputs": [],
   "source": [
    "file_path_clients = \"data/client_datasets/\"  # Path to the directory containing training data for each client\n",
    "\n",
    "# Lists to store training features and labels DataFrames for each client\n",
    "train_features_dfs = []\n",
    "train_labels_dfs = []\n",
    "\n",
    "# Loop over the 10 clients\n",
    "for client_id in range(1, 11):\n",
    "    # Load training features and labels for the current client\n",
    "    features_df = pd.read_csv(f\"{file_path_clients}client_{client_id}_features.csv\", header=None)\n",
    "    labels_df = pd.read_csv(f\"{file_path_clients}client_{client_id}_labels.csv\", header=None)\n",
    "\n",
    "    # Append the loaded data to the lists\n",
    "    train_features_dfs.append(features_df)\n",
    "    train_labels_dfs.append(labels_df)\n",
    "\n",
    "# Load test features and labels\n",
    "test_features_df = pd.read_csv('data/test_features.csv', header=None)\n",
    "test_labels_df = pd.read_csv('data/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22246541-b81d-4ba7-82e6-12e4690578d2",
   "metadata": {},
   "source": [
    "**Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6352e7b-165a-4327-85b0-dddf80a64227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Checks for missing (NaN) values in a DataFrame.\n",
    "\n",
    "    Prints the total number of missing values and \n",
    "    the row indices where they occur, if any.\n",
    "    \"\"\"\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    \n",
    "    if total_missing > 0:\n",
    "        print(f\"Missing values found: {total_missing}\")\n",
    "        missing_rows = df[df.isnull().any(axis=1)]\n",
    "        print(f\"Rows with missing values:\\n{missing_rows.index.tolist()}\")\n",
    "    else:\n",
    "        print(\"No missing values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2ebb38-aae4-4782-9502-1e4a85392d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training data (features and labels):\n",
      "\n",
      "Client 1\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 2\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 3\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 4\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 5\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 6\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 7\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 8\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 9\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Client 10\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n",
      "\n",
      "Checking test data (features and labels):\n",
      "- Features:\n",
      "No missing values found.\n",
      "- Labels:\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking training data (features and labels):\")\n",
    "for i in range(10):  # 10 clients\n",
    "    print(f\"\\nClient {i+1}\")\n",
    "    print(\"- Features:\")\n",
    "    check_missing_values(train_features_dfs[i])\n",
    "    print(\"- Labels:\")\n",
    "    check_missing_values(train_labels_dfs[i])\n",
    "print(\"\\nChecking test data (features and labels):\")\n",
    "print(\"- Features:\")\n",
    "check_missing_values(test_features_df)\n",
    "print(\"- Labels:\")\n",
    "check_missing_values(test_labels_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0e744-56ff-482d-a50c-5b813ac82178",
   "metadata": {},
   "source": [
    "No cleaning is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ec3ce-3668-4b19-8b43-50c2168187cc",
   "metadata": {},
   "source": [
    "**Obtain the data proportion associated to each client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ad4fc6-846e-4fb0-8143-69dc4fd45150",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_client_1 = len(train_features_dfs[0])\n",
    "num_samples_client_2 = len(train_features_dfs[1])\n",
    "num_samples_client_3 = len(train_features_dfs[2])\n",
    "num_samples_client_4 = len(train_features_dfs[3])\n",
    "num_samples_client_5 = len(train_features_dfs[4])\n",
    "num_samples_client_6 = len(train_features_dfs[5])\n",
    "num_samples_client_7 = len(train_features_dfs[6])\n",
    "num_samples_client_8 = len(train_features_dfs[7])\n",
    "num_samples_client_9 = len(train_features_dfs[8])\n",
    "num_samples_client_10 = len(train_features_dfs[9])\n",
    "\n",
    "total_samples = (\n",
    "    num_samples_client_1 + num_samples_client_2 + num_samples_client_3 +\n",
    "    num_samples_client_4 + num_samples_client_5 + num_samples_client_6 +\n",
    "    num_samples_client_7 + num_samples_client_8 + num_samples_client_9 +\n",
    "    num_samples_client_10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596381c-de94-4cba-9e7c-6bc6ec7e6f8e",
   "metadata": {
    "id": "c596381c-de94-4cba-9e7c-6bc6ec7e6f8e"
   },
   "source": [
    "## Part 1 - ML model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0c6d2-499d-4fc9-8866-d6a655e11f41",
   "metadata": {},
   "source": [
    "A FC netwok is selected as ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc3ee6a-a1b7-49c5-b301-5f308273eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=270, hidden_dim_1=128, output_dim=12):\n",
    "        super(PoseClassifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.fc2 = nn.Linear(hidden_dim_1, output_dim)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.03)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        return self.fc2(x)  # logits (CrossEntropyLoss applies softmax internally)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6lnOAvTSQuaT",
   "metadata": {
    "id": "6lnOAvTSQuaT"
   },
   "source": [
    "## Part 2 - Preparation of the FL setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c52d4d-483d-4d6c-82e3-de0532d6fdd6",
   "metadata": {},
   "source": [
    "To perform a realistic simulation of the FL environment, clients must be instantiated separately from orchestrator, hence, we create an independent class for treatig their data and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f054431-2494-44af-8e04-d390cdc5eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, X_train, y_train, local_epochs=5, local_batch_size=32, local_lr=0.01):\n",
    "        \"\"\"\n",
    "        Client object for federated learning.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        client_id : int\n",
    "            Unique client identifier.\n",
    "        X_train : pd.DataFrame\n",
    "            Local feature data.\n",
    "        y_train : pd.DataFrame\n",
    "            Local labels.\n",
    "        local_epochs : int\n",
    "            Number of epochs for local training.\n",
    "        local_batch_size : int\n",
    "            Batch size for local training.\n",
    "        local_lr : float\n",
    "            Learning rate for local optimizer.\n",
    "        \"\"\"\n",
    "        self.id = client_id\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.local_epochs = local_epochs\n",
    "        self.local_batch_size = local_batch_size\n",
    "        self.local_lr = local_lr\n",
    "\n",
    "    def local_train(self, global_model):\n",
    "        \"\"\"\n",
    "        Trains a local copy of the global model on the client's private data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        global_model : torch.nn.Module\n",
    "            The global model whose weights are used to initialize the local copy.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        state_dict : dict\n",
    "            Trained model parameters.\n",
    "        num_samples : int\n",
    "            Number of training samples used.\n",
    "        \"\"\"\n",
    "        # Create and initialize local model\n",
    "        model = type(global_model)()\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "        # Prepare optimizer and loss function\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.local_lr, weight_decay=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Preprocess data: standardize locally\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(self.X_train)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "        # Ensure labels are 0-based and 1D\n",
    "        y_array = self.y_train.values.flatten() - 1\n",
    "        y_tensor = torch.tensor(y_array, dtype=torch.long)\n",
    "\n",
    "        # Build DataLoader\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=self.local_batch_size, shuffle=True)\n",
    "\n",
    "        # Local training loop\n",
    "        model.train()\n",
    "        for epoch in range(self.local_epochs):\n",
    "            total_loss = 0\n",
    "            for xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            #avg_loss = total_loss / len(loader)\n",
    "            #print(f\"Client {self.id} | Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        return model.state_dict(), len(self.X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbb594-fce5-4f59-8d83-5fbcbe32028e",
   "metadata": {},
   "source": [
    "Federated AVG is selected as aggregation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1335b15f-3657-4dde-ae98-26b6afebaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fed_avg(weight_updates, sizes):\n",
    "    \"\"\"\n",
    "    FedAvg with correct handling of float tensors only.\n",
    "    \"\"\"\n",
    "    total_size = sum(sizes)\n",
    "    avg_weights = deepcopy(weight_updates[0])\n",
    "\n",
    "    for key in avg_weights:\n",
    "        if avg_weights[key].dtype not in (torch.float32, torch.float64):\n",
    "            continue  # Skip non-float parameters (like batchnorm counters)\n",
    "\n",
    "        avg_weights[key] = sum(\n",
    "            (client_state[key].float() * (size / total_size))\n",
    "            for client_state, size in zip(weight_updates, sizes)\n",
    "        )\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f94f26-5ea0-4661-a6f9-cf12cf3a46a4",
   "metadata": {},
   "source": [
    "An orchestrator class is defined to organize the distributed training process. Orchestrator does not have access to clients data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb10b9f7-a9d3-43bc-849e-f558659afe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator:\n",
    "    def __init__(self, clients, model_class, num_fl_rounds, tolerance_fl, input_dim=270, hidden_dim_1=128, output_dim=12):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        clients : list of Client\n",
    "            List of clients that contain and manage their own data.\n",
    "        model_class : callable\n",
    "            The PyTorch model class to instantiate the global model.\n",
    "        num_fl_rounds : int\n",
    "            Number of global federated training rounds.\n",
    "        tolerance_fl : float\n",
    "            Minimum weight change threshold to consider convergence.\n",
    "        input_dim, hidden_dim_1, output_dim : int\n",
    "            Architecture parameters for the model.\n",
    "        \"\"\"\n",
    "        self.clients = clients\n",
    "        self.model_class = model_class\n",
    "        self.num_fl_rounds = num_fl_rounds\n",
    "        self.tolerance_fl = tolerance_fl\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim_1 = hidden_dim_1\n",
    "        self.output_dim = output_dim\n",
    "        self.global_model = None\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initializes a fresh instance of the global model.\"\"\"\n",
    "        self.global_model = self.model_class(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim_1=self.hidden_dim_1,\n",
    "            output_dim=self.output_dim\n",
    "        )\n",
    "\n",
    "    def select_clients(self, num_clients):\n",
    "        \"\"\"Randomly selects a subset of clients for a given round.\"\"\"\n",
    "        return random.sample(self.clients, num_clients)\n",
    "\n",
    "    def run_federated_training(self, fedavg_fn, clients_per_round=None):\n",
    "        \"\"\"\n",
    "        Runs the Federated Learning process over several rounds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fedavg_fn : function\n",
    "            Function that aggregates model weights using FedAvg.\n",
    "        clients_per_round : int or None\n",
    "            Number of clients per round (defaults to using all).\n",
    "        \"\"\"\n",
    "        if clients_per_round is None:\n",
    "            clients_per_round = len(self.clients)\n",
    "\n",
    "        prev_weights = None\n",
    "\n",
    "        for round_num in range(self.num_fl_rounds):\n",
    "            print(f\"\\n[Round {round_num + 1}] Selecting clients...\")\n",
    "            selected_clients = self.select_clients(clients_per_round)\n",
    "            #print('selected clients: ', selected_clients)\n",
    "\n",
    "            print(f\"[Round {round_num + 1}] Training local models...\")\n",
    "            updates = []\n",
    "            sizes = []\n",
    "            for client in selected_clients:\n",
    "                weights, size = client.local_train(self.global_model)\n",
    "                updates.append(weights)\n",
    "                sizes.append(size)\n",
    "\n",
    "            print(f\"[Round {round_num + 1}] Aggregating with FedAvg...\")\n",
    "            avg_weights = fedavg_fn(updates, sizes)\n",
    "            #print(self.global_model.state_dict())\n",
    "            self.global_model.load_state_dict(avg_weights)\n",
    "            #print(self.global_model.state_dict())\n",
    "\n",
    "            if prev_weights is not None:\n",
    "                deltas = sum(\n",
    "                    torch.norm(avg_weights[k].float() - prev_weights[k].float()).item()\n",
    "                    for k in avg_weights\n",
    "                    if avg_weights[k].dtype in (torch.float32, torch.float64)\n",
    "                )\n",
    "\n",
    "                print(f\"[Round {round_num + 1}] Weight change: {deltas:.6f}\")\n",
    "                if deltas < self.tolerance_fl:\n",
    "                    print(\"[Convergence reached]\")\n",
    "                    break\n",
    "\n",
    "            prev_weights = {k: v.clone().detach() for k, v in avg_weights.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1qrRF3Z6Q0Vh",
   "metadata": {
    "id": "1qrRF3Z6Q0Vh"
   },
   "source": [
    "## Part 3 - Collaborative training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf8d6c-af7e-4546-a527-e4c963b9f907",
   "metadata": {},
   "source": [
    "Hyperparameter setting: We have decided to perform 100 rounds of FL as we saw that global model's weights did not converge with low number of FL rounds. (With this high number of FL rounds neither). 8 clients were selected per round due to the fact that there are some clients with poorly balanced data, hence reducing the number of clients per round would lead to overfitting within that round and hence not converging global weights. Architecture of our FC presents a funnel structure, with an intermediate layer of 128 neurons. A total of 200 epochs were performed for every client, as by experimentation it turned out to provide slightly better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e63663da-9e30-4cf4-9646-8029540f9910",
   "metadata": {
    "id": "KpIwH78PQ7LM"
   },
   "outputs": [],
   "source": [
    "# Global FL hyperparameters\n",
    "NUM_FL_ROUNDS = 100\n",
    "TOLERANCE_FL = 1e-3\n",
    "CLIENTS_PER_ROUND = 8\n",
    "INPUT_DIM = 270\n",
    "HIDDEN_DIM_1 = 128\n",
    "OUTPUT_DIM = 12\n",
    "\n",
    "# Local training hyperparameters per client\n",
    "LOCAL_EPOCHS = 200\n",
    "LOCAL_BATCH_SIZE=32\n",
    "LOCAL_LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "714beb57-fd96-49d6-9d02-f67670d93da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clients = []\n",
    "\n",
    "for i in range(10):\n",
    "    client = Client(\n",
    "        client_id=i + 1,\n",
    "        X_train=train_features_dfs[i],\n",
    "        y_train=train_labels_dfs[i],\n",
    "        local_epochs=LOCAL_EPOCHS,\n",
    "        local_batch_size=LOCAL_BATCH_SIZE,\n",
    "        local_lr=LOCAL_LR\n",
    "    )\n",
    "    clients.append(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5658d6d7-9729-44be-a84f-80ab490a9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the central FL orchestrator\n",
    "orchestrator = Orchestrator(\n",
    "    clients=clients,\n",
    "    model_class=PoseClassifier,\n",
    "    num_fl_rounds=NUM_FL_ROUNDS,\n",
    "    tolerance_fl=TOLERANCE_FL,\n",
    "    input_dim=INPUT_DIM,\n",
    "    hidden_dim_1=HIDDEN_DIM_1,\n",
    "    output_dim=OUTPUT_DIM\n",
    ")\n",
    "\n",
    "# Instantiate the global model\n",
    "orchestrator.initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6d9059d-41f2-4c47-b22d-f19beb35d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1] Selecting clients...\n",
      "[Round 1] Training local models...\n",
      "[Round 1] Aggregating with FedAvg...\n",
      "\n",
      "[Round 2] Selecting clients...\n",
      "[Round 2] Training local models...\n",
      "[Round 2] Aggregating with FedAvg...\n",
      "[Round 2] Weight change: 5.539872\n",
      "\n",
      "[Round 3] Selecting clients...\n",
      "[Round 3] Training local models...\n",
      "[Round 3] Aggregating with FedAvg...\n",
      "[Round 3] Weight change: 3.813639\n",
      "\n",
      "[Round 4] Selecting clients...\n",
      "[Round 4] Training local models...\n",
      "[Round 4] Aggregating with FedAvg...\n",
      "[Round 4] Weight change: 2.799343\n",
      "\n",
      "[Round 5] Selecting clients...\n",
      "[Round 5] Training local models...\n",
      "[Round 5] Aggregating with FedAvg...\n",
      "[Round 5] Weight change: 2.153313\n",
      "\n",
      "[Round 6] Selecting clients...\n",
      "[Round 6] Training local models...\n",
      "[Round 6] Aggregating with FedAvg...\n",
      "[Round 6] Weight change: 1.986720\n",
      "\n",
      "[Round 7] Selecting clients...\n",
      "[Round 7] Training local models...\n",
      "[Round 7] Aggregating with FedAvg...\n",
      "[Round 7] Weight change: 1.619108\n",
      "\n",
      "[Round 8] Selecting clients...\n",
      "[Round 8] Training local models...\n",
      "[Round 8] Aggregating with FedAvg...\n",
      "[Round 8] Weight change: 1.307996\n",
      "\n",
      "[Round 9] Selecting clients...\n",
      "[Round 9] Training local models...\n",
      "[Round 9] Aggregating with FedAvg...\n",
      "[Round 9] Weight change: 1.101820\n",
      "\n",
      "[Round 10] Selecting clients...\n",
      "[Round 10] Training local models...\n",
      "[Round 10] Aggregating with FedAvg...\n",
      "[Round 10] Weight change: 1.287483\n",
      "\n",
      "[Round 11] Selecting clients...\n",
      "[Round 11] Training local models...\n",
      "[Round 11] Aggregating with FedAvg...\n",
      "[Round 11] Weight change: 1.762342\n",
      "\n",
      "[Round 12] Selecting clients...\n",
      "[Round 12] Training local models...\n",
      "[Round 12] Aggregating with FedAvg...\n",
      "[Round 12] Weight change: 1.722855\n",
      "\n",
      "[Round 13] Selecting clients...\n",
      "[Round 13] Training local models...\n",
      "[Round 13] Aggregating with FedAvg...\n",
      "[Round 13] Weight change: 1.466596\n",
      "\n",
      "[Round 14] Selecting clients...\n",
      "[Round 14] Training local models...\n",
      "[Round 14] Aggregating with FedAvg...\n",
      "[Round 14] Weight change: 2.007974\n",
      "\n",
      "[Round 15] Selecting clients...\n",
      "[Round 15] Training local models...\n",
      "[Round 15] Aggregating with FedAvg...\n",
      "[Round 15] Weight change: 1.828200\n",
      "\n",
      "[Round 16] Selecting clients...\n",
      "[Round 16] Training local models...\n",
      "[Round 16] Aggregating with FedAvg...\n",
      "[Round 16] Weight change: 1.915149\n",
      "\n",
      "[Round 17] Selecting clients...\n",
      "[Round 17] Training local models...\n",
      "[Round 17] Aggregating with FedAvg...\n",
      "[Round 17] Weight change: 1.459058\n",
      "\n",
      "[Round 18] Selecting clients...\n",
      "[Round 18] Training local models...\n",
      "[Round 18] Aggregating with FedAvg...\n",
      "[Round 18] Weight change: 1.032961\n",
      "\n",
      "[Round 19] Selecting clients...\n",
      "[Round 19] Training local models...\n",
      "[Round 19] Aggregating with FedAvg...\n",
      "[Round 19] Weight change: 1.220038\n",
      "\n",
      "[Round 20] Selecting clients...\n",
      "[Round 20] Training local models...\n",
      "[Round 20] Aggregating with FedAvg...\n",
      "[Round 20] Weight change: 1.005656\n",
      "\n",
      "[Round 21] Selecting clients...\n",
      "[Round 21] Training local models...\n",
      "[Round 21] Aggregating with FedAvg...\n",
      "[Round 21] Weight change: 0.976933\n",
      "\n",
      "[Round 22] Selecting clients...\n",
      "[Round 22] Training local models...\n",
      "[Round 22] Aggregating with FedAvg...\n",
      "[Round 22] Weight change: 1.036651\n",
      "\n",
      "[Round 23] Selecting clients...\n",
      "[Round 23] Training local models...\n",
      "[Round 23] Aggregating with FedAvg...\n",
      "[Round 23] Weight change: 0.915182\n",
      "\n",
      "[Round 24] Selecting clients...\n",
      "[Round 24] Training local models...\n",
      "[Round 24] Aggregating with FedAvg...\n",
      "[Round 24] Weight change: 1.154954\n",
      "\n",
      "[Round 25] Selecting clients...\n",
      "[Round 25] Training local models...\n",
      "[Round 25] Aggregating with FedAvg...\n",
      "[Round 25] Weight change: 1.204067\n",
      "\n",
      "[Round 26] Selecting clients...\n",
      "[Round 26] Training local models...\n",
      "[Round 26] Aggregating with FedAvg...\n",
      "[Round 26] Weight change: 0.981558\n",
      "\n",
      "[Round 27] Selecting clients...\n",
      "[Round 27] Training local models...\n",
      "[Round 27] Aggregating with FedAvg...\n",
      "[Round 27] Weight change: 0.712002\n",
      "\n",
      "[Round 28] Selecting clients...\n",
      "[Round 28] Training local models...\n",
      "[Round 28] Aggregating with FedAvg...\n",
      "[Round 28] Weight change: 1.036332\n",
      "\n",
      "[Round 29] Selecting clients...\n",
      "[Round 29] Training local models...\n",
      "[Round 29] Aggregating with FedAvg...\n",
      "[Round 29] Weight change: 0.793913\n",
      "\n",
      "[Round 30] Selecting clients...\n",
      "[Round 30] Training local models...\n",
      "[Round 30] Aggregating with FedAvg...\n",
      "[Round 30] Weight change: 1.307091\n",
      "\n",
      "[Round 31] Selecting clients...\n",
      "[Round 31] Training local models...\n",
      "[Round 31] Aggregating with FedAvg...\n",
      "[Round 31] Weight change: 1.065355\n",
      "\n",
      "[Round 32] Selecting clients...\n",
      "[Round 32] Training local models...\n",
      "[Round 32] Aggregating with FedAvg...\n",
      "[Round 32] Weight change: 0.833231\n",
      "\n",
      "[Round 33] Selecting clients...\n",
      "[Round 33] Training local models...\n",
      "[Round 33] Aggregating with FedAvg...\n",
      "[Round 33] Weight change: 0.676330\n",
      "\n",
      "[Round 34] Selecting clients...\n",
      "[Round 34] Training local models...\n",
      "[Round 34] Aggregating with FedAvg...\n",
      "[Round 34] Weight change: 1.807193\n",
      "\n",
      "[Round 35] Selecting clients...\n",
      "[Round 35] Training local models...\n",
      "[Round 35] Aggregating with FedAvg...\n",
      "[Round 35] Weight change: 1.362969\n",
      "\n",
      "[Round 36] Selecting clients...\n",
      "[Round 36] Training local models...\n",
      "[Round 36] Aggregating with FedAvg...\n",
      "[Round 36] Weight change: 1.521027\n",
      "\n",
      "[Round 37] Selecting clients...\n",
      "[Round 37] Training local models...\n",
      "[Round 37] Aggregating with FedAvg...\n",
      "[Round 37] Weight change: 1.361976\n",
      "\n",
      "[Round 38] Selecting clients...\n",
      "[Round 38] Training local models...\n",
      "[Round 38] Aggregating with FedAvg...\n",
      "[Round 38] Weight change: 1.404627\n",
      "\n",
      "[Round 39] Selecting clients...\n",
      "[Round 39] Training local models...\n",
      "[Round 39] Aggregating with FedAvg...\n",
      "[Round 39] Weight change: 1.309036\n",
      "\n",
      "[Round 40] Selecting clients...\n",
      "[Round 40] Training local models...\n",
      "[Round 40] Aggregating with FedAvg...\n",
      "[Round 40] Weight change: 1.339825\n",
      "\n",
      "[Round 41] Selecting clients...\n",
      "[Round 41] Training local models...\n",
      "[Round 41] Aggregating with FedAvg...\n",
      "[Round 41] Weight change: 0.942187\n",
      "\n",
      "[Round 42] Selecting clients...\n",
      "[Round 42] Training local models...\n",
      "[Round 42] Aggregating with FedAvg...\n",
      "[Round 42] Weight change: 2.029733\n",
      "\n",
      "[Round 43] Selecting clients...\n",
      "[Round 43] Training local models...\n",
      "[Round 43] Aggregating with FedAvg...\n",
      "[Round 43] Weight change: 1.522473\n",
      "\n",
      "[Round 44] Selecting clients...\n",
      "[Round 44] Training local models...\n",
      "[Round 44] Aggregating with FedAvg...\n",
      "[Round 44] Weight change: 1.366380\n",
      "\n",
      "[Round 45] Selecting clients...\n",
      "[Round 45] Training local models...\n",
      "[Round 45] Aggregating with FedAvg...\n",
      "[Round 45] Weight change: 1.299140\n",
      "\n",
      "[Round 46] Selecting clients...\n",
      "[Round 46] Training local models...\n",
      "[Round 46] Aggregating with FedAvg...\n",
      "[Round 46] Weight change: 1.379264\n",
      "\n",
      "[Round 47] Selecting clients...\n",
      "[Round 47] Training local models...\n",
      "[Round 47] Aggregating with FedAvg...\n",
      "[Round 47] Weight change: 1.050978\n",
      "\n",
      "[Round 48] Selecting clients...\n",
      "[Round 48] Training local models...\n",
      "[Round 48] Aggregating with FedAvg...\n",
      "[Round 48] Weight change: 1.137554\n",
      "\n",
      "[Round 49] Selecting clients...\n",
      "[Round 49] Training local models...\n",
      "[Round 49] Aggregating with FedAvg...\n",
      "[Round 49] Weight change: 0.948645\n",
      "\n",
      "[Round 50] Selecting clients...\n",
      "[Round 50] Training local models...\n",
      "[Round 50] Aggregating with FedAvg...\n",
      "[Round 50] Weight change: 1.312210\n",
      "\n",
      "[Round 51] Selecting clients...\n",
      "[Round 51] Training local models...\n",
      "[Round 51] Aggregating with FedAvg...\n",
      "[Round 51] Weight change: 0.817548\n",
      "\n",
      "[Round 52] Selecting clients...\n",
      "[Round 52] Training local models...\n",
      "[Round 52] Aggregating with FedAvg...\n",
      "[Round 52] Weight change: 1.027377\n",
      "\n",
      "[Round 53] Selecting clients...\n",
      "[Round 53] Training local models...\n",
      "[Round 53] Aggregating with FedAvg...\n",
      "[Round 53] Weight change: 0.893707\n",
      "\n",
      "[Round 54] Selecting clients...\n",
      "[Round 54] Training local models...\n",
      "[Round 54] Aggregating with FedAvg...\n",
      "[Round 54] Weight change: 1.304973\n",
      "\n",
      "[Round 55] Selecting clients...\n",
      "[Round 55] Training local models...\n",
      "[Round 55] Aggregating with FedAvg...\n",
      "[Round 55] Weight change: 1.474281\n",
      "\n",
      "[Round 56] Selecting clients...\n",
      "[Round 56] Training local models...\n",
      "[Round 56] Aggregating with FedAvg...\n",
      "[Round 56] Weight change: 1.342545\n",
      "\n",
      "[Round 57] Selecting clients...\n",
      "[Round 57] Training local models...\n",
      "[Round 57] Aggregating with FedAvg...\n",
      "[Round 57] Weight change: 1.529280\n",
      "\n",
      "[Round 58] Selecting clients...\n",
      "[Round 58] Training local models...\n",
      "[Round 58] Aggregating with FedAvg...\n",
      "[Round 58] Weight change: 1.774978\n",
      "\n",
      "[Round 59] Selecting clients...\n",
      "[Round 59] Training local models...\n",
      "[Round 59] Aggregating with FedAvg...\n",
      "[Round 59] Weight change: 1.428696\n",
      "\n",
      "[Round 60] Selecting clients...\n",
      "[Round 60] Training local models...\n",
      "[Round 60] Aggregating with FedAvg...\n",
      "[Round 60] Weight change: 1.303089\n",
      "\n",
      "[Round 61] Selecting clients...\n",
      "[Round 61] Training local models...\n",
      "[Round 61] Aggregating with FedAvg...\n",
      "[Round 61] Weight change: 1.385682\n",
      "\n",
      "[Round 62] Selecting clients...\n",
      "[Round 62] Training local models...\n",
      "[Round 62] Aggregating with FedAvg...\n",
      "[Round 62] Weight change: 1.130653\n",
      "\n",
      "[Round 63] Selecting clients...\n",
      "[Round 63] Training local models...\n",
      "[Round 63] Aggregating with FedAvg...\n",
      "[Round 63] Weight change: 1.403906\n",
      "\n",
      "[Round 64] Selecting clients...\n",
      "[Round 64] Training local models...\n",
      "[Round 64] Aggregating with FedAvg...\n",
      "[Round 64] Weight change: 1.617143\n",
      "\n",
      "[Round 65] Selecting clients...\n",
      "[Round 65] Training local models...\n",
      "[Round 65] Aggregating with FedAvg...\n",
      "[Round 65] Weight change: 1.607786\n",
      "\n",
      "[Round 66] Selecting clients...\n",
      "[Round 66] Training local models...\n",
      "[Round 66] Aggregating with FedAvg...\n",
      "[Round 66] Weight change: 1.260863\n",
      "\n",
      "[Round 67] Selecting clients...\n",
      "[Round 67] Training local models...\n",
      "[Round 67] Aggregating with FedAvg...\n",
      "[Round 67] Weight change: 1.724331\n",
      "\n",
      "[Round 68] Selecting clients...\n",
      "[Round 68] Training local models...\n",
      "[Round 68] Aggregating with FedAvg...\n",
      "[Round 68] Weight change: 1.246208\n",
      "\n",
      "[Round 69] Selecting clients...\n",
      "[Round 69] Training local models...\n",
      "[Round 69] Aggregating with FedAvg...\n",
      "[Round 69] Weight change: 1.421650\n",
      "\n",
      "[Round 70] Selecting clients...\n",
      "[Round 70] Training local models...\n",
      "[Round 70] Aggregating with FedAvg...\n",
      "[Round 70] Weight change: 0.911998\n",
      "\n",
      "[Round 71] Selecting clients...\n",
      "[Round 71] Training local models...\n",
      "[Round 71] Aggregating with FedAvg...\n",
      "[Round 71] Weight change: 0.785045\n",
      "\n",
      "[Round 72] Selecting clients...\n",
      "[Round 72] Training local models...\n",
      "[Round 72] Aggregating with FedAvg...\n",
      "[Round 72] Weight change: 1.214267\n",
      "\n",
      "[Round 73] Selecting clients...\n",
      "[Round 73] Training local models...\n",
      "[Round 73] Aggregating with FedAvg...\n",
      "[Round 73] Weight change: 1.552071\n",
      "\n",
      "[Round 74] Selecting clients...\n",
      "[Round 74] Training local models...\n",
      "[Round 74] Aggregating with FedAvg...\n",
      "[Round 74] Weight change: 1.067218\n",
      "\n",
      "[Round 75] Selecting clients...\n",
      "[Round 75] Training local models...\n",
      "[Round 75] Aggregating with FedAvg...\n",
      "[Round 75] Weight change: 0.687223\n",
      "\n",
      "[Round 76] Selecting clients...\n",
      "[Round 76] Training local models...\n",
      "[Round 76] Aggregating with FedAvg...\n",
      "[Round 76] Weight change: 1.051117\n",
      "\n",
      "[Round 77] Selecting clients...\n",
      "[Round 77] Training local models...\n",
      "[Round 77] Aggregating with FedAvg...\n",
      "[Round 77] Weight change: 0.941286\n",
      "\n",
      "[Round 78] Selecting clients...\n",
      "[Round 78] Training local models...\n",
      "[Round 78] Aggregating with FedAvg...\n",
      "[Round 78] Weight change: 1.203195\n",
      "\n",
      "[Round 79] Selecting clients...\n",
      "[Round 79] Training local models...\n",
      "[Round 79] Aggregating with FedAvg...\n",
      "[Round 79] Weight change: 1.580171\n",
      "\n",
      "[Round 80] Selecting clients...\n",
      "[Round 80] Training local models...\n",
      "[Round 80] Aggregating with FedAvg...\n",
      "[Round 80] Weight change: 0.966523\n",
      "\n",
      "[Round 81] Selecting clients...\n",
      "[Round 81] Training local models...\n",
      "[Round 81] Aggregating with FedAvg...\n",
      "[Round 81] Weight change: 0.674388\n",
      "\n",
      "[Round 82] Selecting clients...\n",
      "[Round 82] Training local models...\n",
      "[Round 82] Aggregating with FedAvg...\n",
      "[Round 82] Weight change: 1.110909\n",
      "\n",
      "[Round 83] Selecting clients...\n",
      "[Round 83] Training local models...\n",
      "[Round 83] Aggregating with FedAvg...\n",
      "[Round 83] Weight change: 1.568349\n",
      "\n",
      "[Round 84] Selecting clients...\n",
      "[Round 84] Training local models...\n",
      "[Round 84] Aggregating with FedAvg...\n",
      "[Round 84] Weight change: 1.799309\n",
      "\n",
      "[Round 85] Selecting clients...\n",
      "[Round 85] Training local models...\n",
      "[Round 85] Aggregating with FedAvg...\n",
      "[Round 85] Weight change: 1.312683\n",
      "\n",
      "[Round 86] Selecting clients...\n",
      "[Round 86] Training local models...\n",
      "[Round 86] Aggregating with FedAvg...\n",
      "[Round 86] Weight change: 1.279312\n",
      "\n",
      "[Round 87] Selecting clients...\n",
      "[Round 87] Training local models...\n",
      "[Round 87] Aggregating with FedAvg...\n",
      "[Round 87] Weight change: 1.062146\n",
      "\n",
      "[Round 88] Selecting clients...\n",
      "[Round 88] Training local models...\n",
      "[Round 88] Aggregating with FedAvg...\n",
      "[Round 88] Weight change: 1.164933\n",
      "\n",
      "[Round 89] Selecting clients...\n",
      "[Round 89] Training local models...\n",
      "[Round 89] Aggregating with FedAvg...\n",
      "[Round 89] Weight change: 1.329512\n",
      "\n",
      "[Round 90] Selecting clients...\n",
      "[Round 90] Training local models...\n",
      "[Round 90] Aggregating with FedAvg...\n",
      "[Round 90] Weight change: 1.456331\n",
      "\n",
      "[Round 91] Selecting clients...\n",
      "[Round 91] Training local models...\n",
      "[Round 91] Aggregating with FedAvg...\n",
      "[Round 91] Weight change: 1.489356\n",
      "\n",
      "[Round 92] Selecting clients...\n",
      "[Round 92] Training local models...\n",
      "[Round 92] Aggregating with FedAvg...\n",
      "[Round 92] Weight change: 1.354564\n",
      "\n",
      "[Round 93] Selecting clients...\n",
      "[Round 93] Training local models...\n",
      "[Round 93] Aggregating with FedAvg...\n",
      "[Round 93] Weight change: 1.001000\n",
      "\n",
      "[Round 94] Selecting clients...\n",
      "[Round 94] Training local models...\n",
      "[Round 94] Aggregating with FedAvg...\n",
      "[Round 94] Weight change: 0.839087\n",
      "\n",
      "[Round 95] Selecting clients...\n",
      "[Round 95] Training local models...\n",
      "[Round 95] Aggregating with FedAvg...\n",
      "[Round 95] Weight change: 1.228703\n",
      "\n",
      "[Round 96] Selecting clients...\n",
      "[Round 96] Training local models...\n",
      "[Round 96] Aggregating with FedAvg...\n",
      "[Round 96] Weight change: 0.883864\n",
      "\n",
      "[Round 97] Selecting clients...\n",
      "[Round 97] Training local models...\n",
      "[Round 97] Aggregating with FedAvg...\n",
      "[Round 97] Weight change: 1.461855\n",
      "\n",
      "[Round 98] Selecting clients...\n",
      "[Round 98] Training local models...\n",
      "[Round 98] Aggregating with FedAvg...\n",
      "[Round 98] Weight change: 1.786086\n",
      "\n",
      "[Round 99] Selecting clients...\n",
      "[Round 99] Training local models...\n",
      "[Round 99] Aggregating with FedAvg...\n",
      "[Round 99] Weight change: 1.897900\n",
      "\n",
      "[Round 100] Selecting clients...\n",
      "[Round 100] Training local models...\n",
      "[Round 100] Aggregating with FedAvg...\n",
      "[Round 100] Weight change: 1.284099\n"
     ]
    }
   ],
   "source": [
    "# Start federated training across rounds\n",
    "orchestrator.run_federated_training(\n",
    "    fedavg_fn = fed_avg,\n",
    "    clients_per_round=CLIENTS_PER_ROUND\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc41a4e-386b-4294-8bec-2114d7d65c0d",
   "metadata": {},
   "source": [
    "The global model did not converge, however, the model gave much better results when not trained distributely, but we were not able to find where does the problem come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "791b8eb8-5604-417f-896d-20ade0ab12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set from CSV\n",
    "test_features_df = pd.read_csv('data/test_features.csv', header=None)\n",
    "test_labels_df = pd.read_csv('data/test_labels.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38e050d4-e795-47bf-b5b4-1e81950ccbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_df, y_test_df):\n",
    "    \"\"\"\n",
    "    Evaluates the global model on the provided test dataset.\n",
    "\n",
    "    This function computes predictions using the trained model and compares them \n",
    "    against the ground truth labels, returning the overall accuracy and confusion matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The trained PyTorch model (e.g., global model after federated training).\n",
    "    X_test_df : pd.DataFrame\n",
    "        Test set features with shape (n_samples, n_features).\n",
    "    y_test_df : pd.DataFrame\n",
    "        Test set labels with values in the range [1, 12].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints test accuracy and displays the confusion matrix.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Labels are shifted to the range [0, 11] before evaluation to match model output indexing.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X_test_df.values, dtype=torch.float32)\n",
    "    y_true = y_test_df.values.ravel() - 1  # Convert labels to 0-based indexing\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        y_pred = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\n🧪 Final Test Accuracy: {acc:.4f}\")\n",
    "    print(\"📊 Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6fbd500-4f39-432f-a77d-b3757b293aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Final Test Accuracy: 0.1480\n",
      "📊 Confusion Matrix:\n",
      "[[ 1 21  0  5  1 12  0  0 14  0  2  1]\n",
      " [ 0 22  0 11  1  9  0  0  3  0  2  3]\n",
      " [ 0 21  0  8  0 16  0  0  0  0  5  6]\n",
      " [ 0 18  0  9  4  8  0  0  1  0  3  4]\n",
      " [ 0 23  0  1  7  8  0  0  8  0  0  3]\n",
      " [ 0 17  0  8  3 17  0  0  0  0  1  1]\n",
      " [ 0 14  0  4  1  9  0  0  3  0  1  5]\n",
      " [ 0  8  0  2  0  5  0  0  1  0  1  0]\n",
      " [ 0  4  0  3  0  1  0  0  4  0  0  0]\n",
      " [ 0 34  0  2  3 13  0  0  0  4  5  2]\n",
      " [ 0 24  0  4  1  5  0  0  5  0  9  4]\n",
      " [ 0  7  0  0  0  2  0  0  0  0  1  1]]\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "evaluate_model(orchestrator.global_model, test_features_df, test_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a029f-740d-4358-b02d-a38c4cbfa3fc",
   "metadata": {},
   "source": [
    "Confusion matrix shows that there are some poses (2, 6, 8) for which the model did not give any results. We think that overfitting "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
